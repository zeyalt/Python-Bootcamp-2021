{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1249be3",
   "metadata": {},
   "source": [
    "# Passage Pathing\n",
    "\n",
    "The analysis that follows pertains to the twelfth day of the [Python Problem-Solving Bootcamp](https://mathspp.com/pythonbootcamp).\n",
    "\n",
    "In the analysis that follows you may be confronted with code that you do not understand, especially as you reach the end of the explanation of each part.\n",
    "\n",
    "If you find functions that you didn't know before, remember to [check the docs](https://docs.python.org/3/) for those functions and play around with them in the REPL.\n",
    "This is written to be increasing in difficulty (within each part of the problem), so it is understandable if it gets harder as you keep reading.\n",
    "That's perfectly fine, you don't have to understand everything _right now_, especially because I can't know for sure what _your level_ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c2f07",
   "metadata": {},
   "source": [
    "## Part 1 problem statement\n",
    "\n",
    "(From [Advent of Code 2021, day 12](https://adventofcode.com/2021/day/12))\n",
    "\n",
    "\n",
    "With your submarine's subterranean subsystems subsisting suboptimally, the only way you're getting out of this cave anytime soon is by finding a path yourself. Not just _a_ path - the only way to know if you've found the _best_ path is to find _all_ of them.\n",
    "\n",
    "Fortunately, the sensors are still mostly working, and so you build a rough map of the remaining caves (your puzzle input). For example:\n",
    "\n",
    "```\n",
    "start-A\n",
    "start-b\n",
    "A-c\n",
    "A-b\n",
    "b-d\n",
    "A-end\n",
    "b-end\n",
    "```\n",
    "\n",
    "This is a list of how all of the caves are connected. You start in the cave named `start`, and your destination is the cave named `end`. An entry like `b-d` means that cave `b` is connected to cave `d` - that is, you can move between them.\n",
    "\n",
    "So, the above cave system looks roughly like this:\n",
    "\n",
    "```\n",
    "    start\n",
    "    /   \\\n",
    "c--A-----b--d\n",
    "    \\   /\n",
    "     end\n",
    "```\n",
    "\n",
    "Your goal is to find the number of distinct _paths_ that start at `start`, end at `end`, and don't visit small caves more than once. There are two types of caves: _big_ caves (written in uppercase, like `A`) and _small_ caves (written in lowercase, like `b`). It would be a waste of time to visit any small cave more than once, but big caves are large enough that it might be worth visiting them multiple times. So, all paths you find should _visit small caves at most once_, and can _visit big caves any number of times_.\n",
    "\n",
    "Given these rules, there are `10` paths through this example cave system:\n",
    "\n",
    "```\n",
    "start,A,b,A,c,A,end\n",
    "start,A,b,A,end\n",
    "start,A,b,end\n",
    "start,A,c,A,b,A,end\n",
    "start,A,c,A,b,end\n",
    "start,A,c,A,end\n",
    "start,A,end\n",
    "start,b,A,c,A,end\n",
    "start,b,A,end\n",
    "start,b,end\n",
    "```\n",
    "\n",
    "(Each line in the above list corresponds to a single path; the caves visited by that path are listed in the order they are visited and separated by commas.)\n",
    "\n",
    "Note that in this cave system, cave `d` is never visited by any path: to do so, cave `b` would need to be visited twice (once on the way to cave `d` and a second time when returning from cave `d`), and since cave `b` is small, this is not allowed.\n",
    "\n",
    "Here is a slightly larger example:\n",
    "\n",
    "```\n",
    "dc-end\n",
    "HN-start\n",
    "start-kj\n",
    "dc-start\n",
    "dc-HN\n",
    "LN-dc\n",
    "HN-end\n",
    "kj-sa\n",
    "kj-HN\n",
    "kj-dc\n",
    "```\n",
    "\n",
    "The `19` paths through it are as follows:\n",
    "\n",
    "```\n",
    "start,HN,dc,HN,end\n",
    "start,HN,dc,HN,kj,HN,end\n",
    "start,HN,dc,end\n",
    "start,HN,dc,kj,HN,end\n",
    "start,HN,end\n",
    "start,HN,kj,HN,dc,HN,end\n",
    "start,HN,kj,HN,dc,end\n",
    "start,HN,kj,HN,end\n",
    "start,HN,kj,dc,HN,end\n",
    "start,HN,kj,dc,end\n",
    "start,dc,HN,end\n",
    "start,dc,HN,kj,HN,end\n",
    "start,dc,end\n",
    "start,dc,kj,HN,end\n",
    "start,kj,HN,dc,HN,end\n",
    "start,kj,HN,dc,end\n",
    "start,kj,HN,end\n",
    "start,kj,dc,HN,end\n",
    "start,kj,dc,end\n",
    "```\n",
    "\n",
    "Finally, this even larger example has `226` paths through it:\n",
    "\n",
    "```\n",
    "fs-end\n",
    "he-DX\n",
    "fs-he\n",
    "start-DX\n",
    "pj-DX\n",
    "end-zg\n",
    "zg-sl\n",
    "zg-pj\n",
    "pj-he\n",
    "RW-he\n",
    "fs-DX\n",
    "pj-RW\n",
    "zg-RW\n",
    "start-pj\n",
    "he-WI\n",
    "zg-he\n",
    "pj-fs\n",
    "start-RW\n",
    "```\n",
    "\n",
    "_How many paths through this cave system are there that visit small caves at most once?_\n",
    "\n",
    "_Using the input file `input.txt`, the result should be `3410`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67606f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Set this to the correct path for you!\n",
    "INPUT_FILE = \"data/input.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f901484",
   "metadata": {},
   "source": [
    "## Representing the graph as a list of edges\n",
    "\n",
    "When you have a series of points (or positions, or places) that are connected amongst each other, you have a graph.\n",
    "A graph is a (mathematical) object composed of a set of vertices and a set of edges, where the edges represent connections vertices.\n",
    "Graphs crop up in all sorts of domains because your set of vertices can be anything, and your set of edges can be any sort of relationship between the vertices.\n",
    "\n",
    "Sometimes, it is obvious that you are dealing with a graph.\n",
    "Other times, it's less obvious.\n",
    "This time, it's quite clear that we have a graph at hands.\n",
    "\n",
    "Graphs can be represented in many different ways, and you have to pick the most convenient way for you, whenever you work with a graph.\n",
    "\n",
    "The first way we are going to go over is the [list of edges](https://en.wikipedia.org/wiki/Edge_list), which corresponds to the way the input is given in this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb761720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['yb', 'start'],\n",
       " ['de', 'vd'],\n",
       " ['rj', 'yb'],\n",
       " ['rj', 'VP'],\n",
       " ['OC', 'de'],\n",
       " ['MU', 'de'],\n",
       " ['end', 'DN'],\n",
       " ['vd', 'end'],\n",
       " ['WK', 'vd'],\n",
       " ['rj', 'de'],\n",
       " ['DN', 'vd'],\n",
       " ['start', 'VP'],\n",
       " ['DN', 'yb'],\n",
       " ['vd', 'MU'],\n",
       " ['DN', 'rj'],\n",
       " ['de', 'VP'],\n",
       " ['yb', 'OC'],\n",
       " ['start', 'rj'],\n",
       " ['oa', 'MU'],\n",
       " ['yb', 'de'],\n",
       " ['oa', 'VP'],\n",
       " ['jv', 'MU'],\n",
       " ['yb', 'MU'],\n",
       " ['end', 'OC']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    graph_edges = [line.strip().split(\"-\") for line in f.readlines()]\n",
    "graph_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5544e2",
   "metadata": {},
   "source": [
    "When representing a graph as a list of edges, it is generally helpful to split the edge into the two vertices.\n",
    "Sometimes, the edges are oriented (which means that information only flows in one direction) and sometimes the edge has no orientation.\n",
    "\n",
    "For example, in a family tree, the direction of an arrow can be used to represent parenthood.\n",
    "Thus, if `A` is `B`'s parent, certainly `B` can't be `A`'s parent.\n",
    "On the other hand, if edges represent connections between cities, if a city `A` is connected to a city `B`, then the city `B` is also connected to the city `A`.\n",
    "\n",
    "In our case, we don't have oriented edges (because if a cave `A` is connected to a cave `B`, then the cave `B` is also connected to the cave `A`).\n",
    "\n",
    "The problem statement concerns itself with navigating through a cave system, so, given this graph representation, how could we figure out the caves that can be visited from a specific cave?\n",
    "\n",
    "Let's write some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0248ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours(graph, cave):\n",
    "    neighbs = []\n",
    "    for edge in graph:\n",
    "        if cave in edge:\n",
    "            neighbs.append(edge[0] if edge[1] == cave else edge[1])\n",
    "    return neighbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8278c9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yb', 'VP', 'rj']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbours(graph_edges, \"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5b7f4",
   "metadata": {},
   "source": [
    "This seems like a promising start.\n",
    "\n",
    "Now, there are three things we can do to our graph representation:\n",
    "\n",
    " - do nothing;\n",
    " - reverse each edge and add it to the list; or\n",
    " - change representation.\n",
    "\n",
    "The first option has the advantage that we have no more work to do now, although we might pay that later if it turns out that this representation has any defficiencies.\n",
    "\n",
    "The second option has the advantage that it becomes easier to figure out where one can go from a single cave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6e2dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VP', 'rj', 'yb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    graph_edges = [line.strip().split(\"-\") for line in f.readlines()]\n",
    "graph_edges += [edge[::-1] for edge in graph_edges]\n",
    "\n",
    "def neighbours(graph, cave):\n",
    "    return [dest for source, dest in graph if source == cave]\n",
    "\n",
    "neighbours(graph_edges, \"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2cb31",
   "metadata": {},
   "source": [
    "The third option has the advantage that we get to play around with more graph representations.\n",
    "Let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bf303",
   "metadata": {},
   "source": [
    "## Representing the graph as an adjacency \"matrix\"\n",
    "\n",
    "Another common way of representing a graph is through an [adjancecy matrix](https://en.wikipedia.org/wiki/Adjacency_matrix).\n",
    "An adjacency matrix is a matrix where each row and column represents a vertex, or a node.\n",
    "If there is an edge between two vertices, the corresponding entry in the matrix is set to one.\n",
    "If there is no edge between two vertices, the corresponding entry in the matrix is set to zero.\n",
    "\n",
    "We have worked a bit with 2D arrays already, but let's go back to an idea from the previous analysis and use a dictionary to represent our matrix.\n",
    "\n",
    "After reading in the edge list, we can figure out all the vertices in our graph and initialise the adjacency matrix for the graph.\n",
    "Then, finding the neighbours of a single vertex is a matter of looking for positions in the matrix that are set to true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55befc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yb', 'rj', 'VP']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    graph_edges = [line.strip().split(\"-\") for line in f.readlines()]\n",
    "\n",
    "# Read a set of nodes to remove duplicates and convert to list to preserve order.\n",
    "NODES = list({node for edge in graph_edges for node in edge})\n",
    "\n",
    "graph = dict.fromkeys(product(NODES, NODES), False)\n",
    "for v1, v2 in graph_edges:\n",
    "    graph[(v1, v2)] = True\n",
    "    graph[(v2, v1)] = True\n",
    "\n",
    "def neighbours(graph, cave):\n",
    "    return [dest for dest in NODES if graph[(cave, dest)]]\n",
    "\n",
    "neighbours(graph, \"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c07fbd4",
   "metadata": {},
   "source": [
    "This is an interesting of representing the graph, but adjacency matrices are typically more useful when we can actually use a _matrix_ to do some computations with it.\n",
    "Thus, this fake matrix representation with a dictionary isn't going to work very well, but it may lead us into a better representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800ab50",
   "metadata": {},
   "source": [
    "## Representing the graph as an adjacency list\n",
    "\n",
    "Instead of keeping a dictionary which contains edges as keys and Boolean values as, well, values, let's do something more useful.\n",
    "\n",
    "We don't want to have to iterate over the whole list `NODES` just to find out what vertices are adjacent to a given vertex.\n",
    "Instead of coupling the vertices like that in the keys to the dictionary `graph`, let's have a key _per vertex_, and then each vertex is associated with a list of all the vertices that are connected to it.\n",
    "\n",
    "This is what's commonly called an [adjacency list](https://en.wikipedia.org/wiki/Adjacency_list) and makes it _very_ convenient to traverse the graph.\n",
    "Instead of needing to call the function `neighbours`, we can just use a key to access the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10bd330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yb', 'VP', 'rj']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    graph_edges = [line.strip().split(\"-\") for line in f.readlines()]\n",
    "\n",
    "graph = {}\n",
    "for v1, v2 in graph_edges:\n",
    "    if v1 not in graph:\n",
    "        graph[v1] = []\n",
    "    if v2 not in graph:\n",
    "        graph[v2] = []\n",
    "    graph[v1].append(v2)\n",
    "    graph[v2].append(v1)\n",
    "\n",
    "graph[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ead0f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yb': ['start', 'rj', 'DN', 'OC', 'de', 'MU'],\n",
       " 'start': ['yb', 'VP', 'rj'],\n",
       " 'de': ['vd', 'OC', 'MU', 'rj', 'VP', 'yb'],\n",
       " 'vd': ['de', 'end', 'WK', 'DN', 'MU'],\n",
       " 'rj': ['yb', 'VP', 'de', 'DN', 'start'],\n",
       " 'VP': ['rj', 'start', 'de', 'oa'],\n",
       " 'OC': ['de', 'yb', 'end'],\n",
       " 'MU': ['de', 'vd', 'oa', 'jv', 'yb'],\n",
       " 'end': ['DN', 'vd', 'OC'],\n",
       " 'DN': ['end', 'vd', 'yb', 'rj'],\n",
       " 'WK': ['vd'],\n",
       " 'oa': ['MU', 'VP'],\n",
       " 'jv': ['MU']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcacc611",
   "metadata": {},
   "source": [
    "There you go, a graph represented as an adjacency list!\n",
    "\n",
    "Now, in order to implement this in a proper way, we should actually make use of the class `defaultdict` from the module `collections`, which we have seen a couple of times already.\n",
    "By using the built-in `list` as the object constructor, we can make it so that the `defaultdict` returns an empty list for a key that has never been used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5dd11b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yb', 'VP', 'rj']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    graph_edges = [line.strip().split(\"-\") for line in f.readlines()]\n",
    "\n",
    "graph = defaultdict(list)\n",
    "for v1, v2 in graph_edges:\n",
    "    graph[v1].append(v2)\n",
    "    graph[v2].append(v1)\n",
    "\n",
    "graph[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd95156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'yb': ['start', 'rj', 'DN', 'OC', 'de', 'MU'],\n",
       "             'start': ['yb', 'VP', 'rj'],\n",
       "             'de': ['vd', 'OC', 'MU', 'rj', 'VP', 'yb'],\n",
       "             'vd': ['de', 'end', 'WK', 'DN', 'MU'],\n",
       "             'rj': ['yb', 'VP', 'de', 'DN', 'start'],\n",
       "             'VP': ['rj', 'start', 'de', 'oa'],\n",
       "             'OC': ['de', 'yb', 'end'],\n",
       "             'MU': ['de', 'vd', 'oa', 'jv', 'yb'],\n",
       "             'end': ['DN', 'vd', 'OC'],\n",
       "             'DN': ['end', 'vd', 'yb', 'rj'],\n",
       "             'WK': ['vd'],\n",
       "             'oa': ['MU', 'VP'],\n",
       "             'jv': ['MU']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48009066",
   "metadata": {},
   "source": [
    "Finally, because the processing we are doing is very basic, we can build the graph directly when we read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ca5f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yb', 'VP', 'rj']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "\n",
    "graph[\"start\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c5e19",
   "metadata": {},
   "source": [
    "Now, in order to solve the actual problem, we need to employ a search algorithm in our graph.\n",
    "\n",
    "When working with graphs, there are many algorithms to compute specific things with those graphs.\n",
    "For example, you can try finding the shortest distance between two vertices, or you might want to compute a tree that represents your graph, or you might want to check if the graph has cycles, or ...\n",
    "\n",
    "However, there are two basic algorithms that are useful for when you need to do some generic work in/with a graph, and those two algorithms are breadth-first search and depth-first search.\n",
    "We will use both to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea513dfd",
   "metadata": {},
   "source": [
    "## Breadth-first search (BFS)\n",
    "\n",
    "The idea of [breadth-first search](https://en.wikipedia.org/wiki/Breadth-first_search) (BFS) is that, when you reach a new vertex, you first take a look at all the vertices that surround you, and only then deepen your search by following into a new vertex.\n",
    "\n",
    "This is to contrast with [depth-first search](https://en.wikipedia.org/wiki/Depth-first_search), because when you reach a new vertex, you immediately start exploring deeper into the graph before looking around you and checking what options you have available.\n",
    "\n",
    "Typically, we use a search algorithm to find something specific.\n",
    "However, in this case, we just want to explore the whole graph and count how many paths we find.\n",
    "We can frame this as searching for the vertex labeled `\"end\"`.\n",
    "\n",
    "A BFS implementation follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4f98322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "        \n",
    "count = 0\n",
    "queue = deque([(\"start\", )])\n",
    "while queue:\n",
    "    path_so_far = queue.pop()\n",
    "    if path_so_far[-1] == \"end\":\n",
    "        count += 1\n",
    "        continue\n",
    "\n",
    "    for neighbour in graph[path_so_far[-1]]:\n",
    "        if not (neighbour.lower() == neighbour and neighbour in path_so_far):\n",
    "            queue.appendleft(path_so_far + (neighbour, ))\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bacfd",
   "metadata": {},
   "source": [
    "The algorithm above creates a queue (by leveraging the class `deque` from the module `collections`) and seeds it with the `\"start\"` cave.\n",
    "Then, while there are paths to explore in the cave, we pick up the next path.\n",
    "After we make sure the path isn't finished yet, we explore all possible caves and add the valid paths for later exploration.\n",
    "A valid path is a path that doesn't contain a repeated lowercase cavern.\n",
    "\n",
    "The code we wrote above can be cleaned up a bit.\n",
    "For one, we are checking if the neighbouring cave `neighbour` is a lowercase cave by checking `neighbour.lower() == neighbour`.\n",
    "This is redundant, because strings have a method `.islower` that checks just that.\n",
    "\n",
    "Secondly, we can use starred assignment to destructure the last visited vertex into a variable of its own, making the code a bit cleaner.\n",
    "\n",
    "Lastly, we can use a list comprehension, and the method `.extendleft`, to insert a series of elements into the queue in one fell swoop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6cf4f18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "queue = deque([[\"start\"]])\n",
    "while queue:\n",
    "    path = *_, last_visited = queue.pop()  # <-\n",
    "    if last_visited == \"end\":\n",
    "        count += 1\n",
    "        continue\n",
    "\n",
    "    queue.extendleft([\n",
    "        path + [neighbour] for neighbour in graph[last_visited]  # <-\n",
    "        if not (neighbour.islower() and neighbour in path)  # <-\n",
    "    ])\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fab4a6",
   "metadata": {},
   "source": [
    "BFS is a staple of graph algorithms, but one thing I don't appreciate is that the queue that holds the paths that have to be processed can grow quite a bit.\n",
    "\n",
    "Switching to DFS can help with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506b83e",
   "metadata": {},
   "source": [
    "## Depth-first search (DFS)\n",
    "\n",
    "As mentioned above, [depth-first search](https://en.wikipedia.org/wiki/Depth-first_search) is a graph search algorithm that prioritises exhausting search paths over exploring multiple possibilities.\n",
    "In other words, DFS _first_ tries to complete a path, and only then explores different routes.\n",
    "\n",
    "By taking our BFS code from above, we can change it from breadh-first into depth-first by a simple change of data structure.\n",
    "By using a queue in breadth-first search, and by putting new elements on the queue on one side and popping them from the other, we manage to prioritise exploration.\n",
    "If we switch to a stack, where we put and pop elements from the same end, we will be prioritising finishing a path before exploring new paths.\n",
    "\n",
    "Here is a possible DFS implementation with a stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebcd0fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "        \n",
    "count = 0\n",
    "queue = deque([[\"start\"]])\n",
    "while queue:\n",
    "    path = *_, last_visited = queue.pop()\n",
    "    if last_visited == \"end\":\n",
    "        count += 1\n",
    "        continue\n",
    "\n",
    "    queue.extend([  # <- changed from `extendleft` to `extend`.\n",
    "        path + [neighbour] for neighbour in graph[last_visited]\n",
    "        if not (neighbour.islower() and neighbour in path)\n",
    "    ])\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14cd0a9",
   "metadata": {},
   "source": [
    "The code is _identical_ to the BFS from above, except the single method call where the comment is, which was changed from `.extendleft` to `.extend`.\n",
    "Everything else is 100% the same.\n",
    "\n",
    "Of course it shouldn't, though, because now we are using a stack and not a queue.\n",
    "Thus, the name of the variable should change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3af6f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "stack = deque([[\"start\"]])\n",
    "while stack:\n",
    "    path = *_, last_visited = stack.pop()\n",
    "    if last_visited == \"end\":\n",
    "        count += 1\n",
    "        continue\n",
    "\n",
    "    stack.extend([\n",
    "        path + [neighbour] for neighbour in graph[last_visited]\n",
    "        if not (neighbour.islower() and neighbour in path)\n",
    "    ])\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e436ff",
   "metadata": {},
   "source": [
    "## Recursive DFS\n",
    "\n",
    "Recursion and iteration are essentially equivalent, which means that, whatever you did with one, you should be able to do with the other.\n",
    "Now, of course this is simpler some times and more difficult in other times.\n",
    "However, when you have some stack-based iteration, that should be easy to rewrite as a recursive function.\n",
    "\n",
    "For the sake of completeness, let us experiment with a recursive version of DFS, by means of an auxiliary function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3a8b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3410"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "        \n",
    "def dfs(graph, path_so_far):\n",
    "    *_, last_visited = path_so_far\n",
    "    if last_visited == \"end\":\n",
    "        return 1\n",
    "\n",
    "    count = 0\n",
    "    for neighbour in graph[path_so_far[-1]]:\n",
    "        if not (neighbour.islower() and neighbour in path_so_far):\n",
    "            count += dfs(graph, path_so_far + [neighbour])\n",
    "    return count\n",
    "\n",
    "dfs(graph, [\"start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5e319",
   "metadata": {},
   "source": [
    "This recursive definition is _very_ similar to the one with the `while` loop, except that we do not have to keep track of an explicit stack of options to explore.\n",
    "The (recursive) call stack takes care of that for us.\n",
    "\n",
    "Now, at this point you should know by heart that modification I am going to suggest next.\n",
    "If you look at the end of the function `dfs`, you will notice, once more, the pattern of a reduction!\n",
    "In particular, of `sum`.\n",
    "\n",
    "To make use of `sum` there, we just need to use a list comprehension to apply the function `dfs` recursively to the path extended by each of the neighbours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49760e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3410"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "        \n",
    "def dfs(graph, path_so_far):\n",
    "    *_, last_visited = path_so_far\n",
    "    if last_visited == \"end\":\n",
    "        return 1\n",
    "\n",
    "    return sum(\n",
    "        dfs(graph, path_so_far + [neighbour]) for neighbour in graph[last_visited]\n",
    "        if not (neighbour.islower() and neighbour in path_so_far)\n",
    "    )\n",
    "\n",
    "dfs(graph, [\"start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c10b92",
   "metadata": {},
   "source": [
    "## De Morgan's laws\n",
    "\n",
    "The [De Morgan's laws](https://en.wikipedia.org/wiki/De_Morgan%27s_laws) are two rules that apply to Boolean expressions.\n",
    "De Morgan's laws state that:\n",
    "\n",
    " 1. `not (a and b)` is the same as `(not a) or (not b)`; and\n",
    " 2. `not (a or b)` is the same as `(not a) and (not b)`.\n",
    "\n",
    "By inserting `not`s here and there, they can be used to play around with Boolean expressions in many different ways.\n",
    "What I personally find interesting is that De Morgan's laws make very much intuitive sense.\n",
    "\n",
    "For example, in the above, we only want to consider a new vertex into the path `if not (neighbour.islower() and neighbour in path_so_far)`.\n",
    "In English words, if it is not the case that the neighbour is a lowercase cave **and** is already in the path.\n",
    "Of course, we could try to write this in the affirmative.\n",
    "Such an appropriate refactour could mean “we care about the next vertex if it is an uppercase cave or if it is not in the path yet”, which allows us to rewrite the code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2fd308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3410"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dfs(graph, path_so_far):\n",
    "    *_, last_visited = path_so_far\n",
    "    if last_visited == \"end\":\n",
    "        return 1\n",
    "\n",
    "    return sum(\n",
    "        dfs(graph, path_so_far + [neighbour]) for neighbour in graph[last_visited]\n",
    "        if neighbour.isupper() or neighbour not in path_so_far\n",
    "    )\n",
    "\n",
    "dfs(graph, [\"start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba07f1e",
   "metadata": {},
   "source": [
    "This refactoring of the `if` statement was purely stylistic and I invete the reader to pick whichever version they prefer.\n",
    "I prefer the current one because it maps out better to English, especially because of the `not in` operator:\n",
    "recall that the other alternative starts with `not` and then a set of parenthesis to group everything.\n",
    "\n",
    "On the other hand, the the line of code\n",
    "\n",
    "```py\n",
    "if neighbour.isupper() or neighbour not in path_so_far\n",
    "```\n",
    "\n",
    "reads directly as “this neighbour matters if it is an uppercase cave or if it hasn't been visited yet, before”.\n",
    "\n",
    "We've seen two main graph search algorithms and a couple of different alternative implementations, so let's crack the second part now:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2445e6b6",
   "metadata": {},
   "source": [
    "## Part 2 problem statement\n",
    "\n",
    "(From [Advent of Code 2021, day 12](https://adventofcode.com/2021/day/12))\n",
    "\n",
    "After reviewing the available paths, you realize you might have time to visit a single small cave _twice_. Specifically, big caves can be visited any number of times, a single small cave can be visited at most twice, and the remaining small caves can be visited at most once. However, the caves named `start` and `end` can only be visited _exactly once each_: once you leave the `start` cave, you may not return to it, and once you reach the `end` cave, the path must end immediately.\n",
    "\n",
    "Now, the `36` possible paths through the first example above are:\n",
    "\n",
    "```\n",
    "start,A,b,A,b,A,c,A,end\n",
    "start,A,b,A,b,A,end\n",
    "start,A,b,A,b,end\n",
    "start,A,b,A,c,A,b,A,end\n",
    "start,A,b,A,c,A,b,end\n",
    "start,A,b,A,c,A,c,A,end\n",
    "start,A,b,A,c,A,end\n",
    "start,A,b,A,end\n",
    "start,A,b,d,b,A,c,A,end\n",
    "start,A,b,d,b,A,end\n",
    "start,A,b,d,b,end\n",
    "start,A,b,end\n",
    "start,A,c,A,b,A,b,A,end\n",
    "start,A,c,A,b,A,b,end\n",
    "start,A,c,A,b,A,c,A,end\n",
    "start,A,c,A,b,A,end\n",
    "start,A,c,A,b,d,b,A,end\n",
    "start,A,c,A,b,d,b,end\n",
    "start,A,c,A,b,end\n",
    "start,A,c,A,c,A,b,A,end\n",
    "start,A,c,A,c,A,b,end\n",
    "start,A,c,A,c,A,end\n",
    "start,A,c,A,end\n",
    "start,A,end\n",
    "start,b,A,b,A,c,A,end\n",
    "start,b,A,b,A,end\n",
    "start,b,A,b,end\n",
    "start,b,A,c,A,b,A,end\n",
    "start,b,A,c,A,b,end\n",
    "start,b,A,c,A,c,A,end\n",
    "start,b,A,c,A,end\n",
    "start,b,A,end\n",
    "start,b,d,b,A,c,A,end\n",
    "start,b,d,b,A,end\n",
    "start,b,d,b,end\n",
    "start,b,end\n",
    "```\n",
    "\n",
    "The slightly larger example above now has `103` paths through it, and the even larger example now has `3509` paths through it.\n",
    "\n",
    "Given these new rules, _how many paths through this cave system are there?_\n",
    "\n",
    "_Using the input file `input.txt`, the result should be `98796`._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a6d14",
   "metadata": {},
   "source": [
    "## Different filtering\n",
    "\n",
    "Once more (just like with the previous challenge) it seems that a solid answer to the first part goes a _long_ way to solve the second part.\n",
    "\n",
    "As it turns out, we just need to be slightly more permissive when checking which neighbours are useful.\n",
    "Now, we can accept a repeated lowercase cave if that's the first time it happens.\n",
    "\n",
    "To check if that's happened before, we resort to an auxiliary function and check if there is any lowercase cave that has been visited more than once.\n",
    "On top of that, we have to be careful not to visit the vertices `\"start\"` or `\"end\"` twice.\n",
    "\n",
    "Thankfully, we will never visit the vertex `\"end\"` twice because, as soon as we reach that vertex, we return.\n",
    "In order to avoid the vertex `\"start\"`, we can filter it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d6e81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98796"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict, deque  # <-\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "\n",
    "def has_repeated_cave(path):\n",
    "    caves = Counter([cave for cave in path if cave.islower()])\n",
    "    return max(caves.values()) > 1\n",
    "        \n",
    "def dfs(graph, path):\n",
    "    *_, last_visited = path\n",
    "    if last_visited == \"end\":\n",
    "        return 1\n",
    "\n",
    "    return sum(\n",
    "        dfs(graph, path + [neighb]) for neighb in graph[last_visited]\n",
    "        if neighb != \"start\" and (neighb.isupper() or neighb not in path or not has_repeated_cave(path))\n",
    "    )\n",
    "\n",
    "dfs(graph, [\"start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ecb352",
   "metadata": {},
   "source": [
    "Not only is line 21 _very_ long, it is also wasteful.\n",
    "Notice that `has_repeated_cave(path)` only depends on the path we have so far, and yet we recompute it for every iteration of `neighb` over the possible next neighbours.\n",
    "In order to save some time, we can compute it before the list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011f297d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98796"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dfs(graph, path):\n",
    "    *_, last_visited = path\n",
    "    if last_visited == \"end\":\n",
    "        return 1\n",
    "\n",
    "    can_repeat = not has_repeated_cave(path)\n",
    "    return sum(\n",
    "        dfs(graph, path + [neighb]) for neighb in graph[last_visited]\n",
    "        if neighb != \"start\" and (neighb.isupper() or neighb not in path or can_repeat)\n",
    "    )\n",
    "\n",
    "dfs(graph, [\"start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783158c",
   "metadata": {},
   "source": [
    "This saves some computational power, but we still have a very long line, and very long lines are frowned upon.\n",
    "If your code takes up too much horizontal space, it also ends up being harder to read!\n",
    "\n",
    "The line became much longer because we have to filter out the `\"start\"` cave and because we need to check if we can repeat a lowercase cave, so let's see if we can do something about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b97750",
   "metadata": {},
   "source": [
    "## Removing the initial cave as a destination\n",
    "\n",
    "The issue is that many caves view the `\"start\"` cave as a possible destination, and we have to keep ignoring it over and over again.\n",
    "\n",
    "Another way of dealing with this would boil down to removing the cave `\"start\"` from the adjacency list of all other caves, making it impossible to return to the cave `\"start\"`.\n",
    "In order to remove an item from an adjacency list (which is represented by the built-in type `list`), we can use the `.remove` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e16aca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1, 2, 3, 4]\n",
    "l.remove(3)\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e1489",
   "metadata": {},
   "source": [
    "We just have to be careful with what happens if we call the method `.remove` and the item isn't in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "811232bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6016/1742214712.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "l.remove(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc54115",
   "metadata": {},
   "source": [
    "Thus, we need to prevent the `ValueError` of being thrown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbdc4e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98796"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict, deque\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "\n",
    "for connections in graph.values():\n",
    "    if \"start\" in connections:\n",
    "        connections.remove(\"start\")\n",
    "\n",
    "def has_repeated_cave(path):\n",
    "    caves = Counter([cave for cave in path if cave.islower()])\n",
    "    return max(caves.values()) > 1\n",
    "        \n",
    "def dfs(graph, path):\n",
    "    *_, last_visited = path\n",
    "    if last_visited == \"end\":\n",
    "        return 1\n",
    "\n",
    "    can_repeat = not has_repeated_cave(path)\n",
    "    return sum(\n",
    "        dfs(graph, path + [neighb]) for neighb in graph[last_visited]\n",
    "        if neighb.isupper() or neighb not in path or can_repeat\n",
    "    )\n",
    "\n",
    "dfs(graph, [\"start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654cabc4",
   "metadata": {},
   "source": [
    "By using an `if` statement, we only remove the cave `\"start\"` from the adjacency lists that had it in the first place.\n",
    "However, using an `if` statement to look inside the list `connections` before we try to remove something from it follows the LBYL (Look Before You Leap) coding style, and Python often prefers the EAFP (Easier to Ask Forgiveness than Permission) style.\n",
    "\n",
    "You can read about both styles [in this article](https://mathspp.com/blog/pydonts/eafp-and-lbyl-coding-styles), but the gist of it is that the LBYL is characterised by `if` statements prior to the main action, whereas the EAFP style encloses the main action with a `try` statement.\n",
    "\n",
    "Hence, following the EAFP style, we could write something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfc14b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "\n",
    "for connections in graph.values():\n",
    "    try:\n",
    "        connections.remove(\"start\")\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41402d",
   "metadata": {},
   "source": [
    "This is the EAFP coding style and, in this particular case, saves us from going over the list `connections` twice, but it is kind of a shame that it became so much longer...\n",
    "\n",
    "Thankfully for us, this `try: ... except: ...` block has a very specific pattern: it has a `try`, and the `except` is just a `pass` statement.\n",
    "What do `try` blocks like that mean?\n",
    "They mean we want to try to do something, but we don't care if it fails.\n",
    "For example, in our case, we want to delete the cave `\"start\"` from all adjacency lists.\n",
    "But, if the `.remove` call failed, that's because the cave `\"start\"` wasn't there to begin with, so I don't care about the error, I just want to ignore it.\n",
    "\n",
    "When in situations like this, there is a nice tool for you in the module `contextlib`, called `suppress`: it's a context manager that let's you suppress (that is, ignore) the exceptions you specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d618a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import suppress  # <-\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "\n",
    "for connections in graph.values():\n",
    "    with suppress(ValueError):  # Ignore ValueError's that might get raised.\n",
    "        connections.remove(\"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3b262",
   "metadata": {},
   "source": [
    "## Carrying information about repeating caves\n",
    "\n",
    "The last tweak that we want to make to our function has to do with the information regarding repeated caves.\n",
    "First, for each tentative neighbour, we checked if the path already had repeated caves.\n",
    "Then, we realised that we can do it before that loop to save some time.\n",
    "\n",
    "Now, let's think about this: if at a given point in the path we can't repeat a lowercase cave because we already did, will we be able to do it again later on?\n",
    "No, we won't!\n",
    "So, as soon as we repeat a cave, we can carry that information with us, because we don't need to recompute it every single time.\n",
    "\n",
    "To do this, we will employ a very common technique in recursive programming: we pass some information about the state of the program as an argument!\n",
    "This shouldn't sound mind-blowing, because that's what we are already doing with the list `path`, for example.\n",
    "\n",
    "So, when we are about to call the function `dfs` recursively, we need to figure out how to update the Boolean flags that tells us if we can repeat a lowercase cave or not.\n",
    "When preparing the recursive call, we can say that we have repeated a lowercase cave if we already did it before **or** if we just repeated a lowercase cave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90e27365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98796"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "from contextlib import suppress\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "\n",
    "for connections in graph.values():\n",
    "    with suppress(ValueError):\n",
    "        connections.remove(\"start\")\n",
    "        \n",
    "def dfs(graph, path, has_repeated):\n",
    "    *_, last_visited = path\n",
    "    if last_visited == \"end\":\n",
    "        return 1\n",
    "\n",
    "    return sum(\n",
    "        dfs(graph, path + [neighb], has_repeated or (neighb.islower() and neighb in path))\n",
    "        for neighb in graph[last_visited]\n",
    "        if neighb.isupper() or neighb not in path or not has_repeated\n",
    "    )\n",
    "\n",
    "dfs(graph, [\"start\"], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8669b79",
   "metadata": {},
   "source": [
    "With this Boolean flag, we can even solve both tasks with a single function.\n",
    "For the first problem, we just have to set the Boolean flag `has_repeated` to `True`, as if we had already repeated a lowercase cave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7425b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410\n",
      "98796\n"
     ]
    }
   ],
   "source": [
    "print(dfs(graph, [\"start\"], True))   # Part 1.\n",
    "print(dfs(graph, [\"start\"], False))  # Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc99e59",
   "metadata": {},
   "source": [
    "## Naming matters\n",
    "\n",
    "We have been doing this implicitly, but now I'll call it out.\n",
    "[Naming matters](https://mathspp.com/blog/pydonts/naming-matters).\n",
    "It matters because our brains can only hold a small number of ideas and thoughts at the same time, and giving proper names to things makes it easier to manage them in our heads.\n",
    "\n",
    "For functions, in particular, the name of the function should tell you what the function _does_, and not _how_ it does it.\n",
    "So, in our case, I'm talking about the function `dfs`.\n",
    "The name isn't that great because we used the acronym for the algorithm we implemented, when in fact the function has a very specific purpose: to count paths in a graph.\n",
    "Thus, our function should've had a name that matched that purpose, instead of a name that reflects the internal algorithm being used.\n",
    "\n",
    "In our case, something along the lines of `count_paths` would've worked perfectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ce739c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98796"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "from contextlib import suppress\n",
    "\n",
    "graph = defaultdict(list)\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    for line in f:\n",
    "        v1, v2 = line.strip().split(\"-\")\n",
    "        graph[v1].append(v2)\n",
    "        graph[v2].append(v1)\n",
    "\n",
    "for connections in graph.values():\n",
    "    with suppress(ValueError):\n",
    "        connections.remove(\"start\")\n",
    "        \n",
    "def count_paths(graph, path, has_repeated):  # <-\n",
    "    *_, last_visited = path\n",
    "    if last_visited == \"end\":\n",
    "        return 1\n",
    "\n",
    "    return sum(\n",
    "        count_paths(\n",
    "            graph,\n",
    "            path + [neighb],\n",
    "            has_repeated or (neighb.islower() and neighb in path),\n",
    "        )\n",
    "        for neighb in graph[last_visited]\n",
    "        if neighb.isupper() or neighb not in path or not has_repeated\n",
    "    )\n",
    "\n",
    "count_paths(graph, [\"start\"], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e5f9e",
   "metadata": {},
   "source": [
    "As the name of the function increased, the recursive call line became too long and we had to split it,\n",
    "that's why you see each argument on its own line now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b58c16",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The two classical graph algorithms are _very_ similar, and yet depth-first search is very amenable to a transation into a recursive version, whereas breadth-first search not so much.\n",
    "We also took the chance to look at a couple of different ways of representing graphs and realised first-hand that choosing your data structures wisely is half the job when solving a problem.\n",
    "\n",
    "If you have any questions, suggestions, remarks, recommendations, corrections, or anything else, you can reach out to me [on Twitter](https://twitter.com/mathsppblog) or via email to rodrigo at mathspp dot com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b77f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
